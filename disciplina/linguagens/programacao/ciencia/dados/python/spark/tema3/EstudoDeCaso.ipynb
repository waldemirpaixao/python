{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eec7bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "25/11/09 16:56:11 WARN Utils: Your hostname, null, resolves to a loopback address: 127.0.0.1; using 192.168.1.5 instead (on interface wlp3s0)\n",
      "25/11/09 16:56:11 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/11/09 16:56:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "import json\n",
    "import csv\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "spark = SparkSession.builder.appName(\"EMpresaYAnalseDeDados\").getOrCreate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4f8b842",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gerar_dados_vendas():\n",
    "    produtos = [\"Notebook\",\"Smartphone\", \"Tablet\", \"Fone de Ouvido\", \"Smartwatch\"]\n",
    "    with open('dados_vendas.csv','w', newline='') as arquivo:\n",
    "        escritor = csv.writer(arquivo)\n",
    "        escritor.writerow([\"id_venda\", \"id_produto\", \"produto\", \"quantidade\",\"preco\",\"data\"])\n",
    "        for i in range(1000):\n",
    "            id_produto = random.randint(1,5)\n",
    "            escritor.writerow([i, id_produto,produtos[id_produto-1],random.randint(1,5),\"{:.2f}\".format(random.uniform(100,1000),(datetime.now() - timedelta(days=random.randint(0,30))).strftime(\"%Y-%m-%d %H:%M:%S\"))])\n",
    "\n",
    "def gerar_dados_comportamento_cliente():\n",
    "    acoes = [\"visualizacao\", \"adicionar_ao_carrinho\",\"compra\", \"avaliacao\"]\n",
    "    dados = []\n",
    "    for i in range(1000):\n",
    "        dados.append({\n",
    "            \"id_cliente\": random.randint(1,100),\n",
    "            \"id_produto\":random.randint(1,5),\n",
    "            \"acao\":random.choice(acoes),\n",
    "            \"data_hora\":(datetime.now() - timedelta(minutes=random.randint(0,1440))).isoformat()\n",
    "        })\n",
    "    with open('comportamento_cliente.json','w') as arquivo:\n",
    "        json.dump(dados, arquivo)\n",
    "    \n",
    "    \n",
    "def gerar_dados_estoque():\n",
    "    produtos = [\"Notebook\",\"Smartphone\", \"Tablet\", \"Fone de Ouvido\", \"Smartwatch\"]\n",
    "    with open('dados_estoque.csv','w', newline='') as arquivo:\n",
    "        escritor = csv.writer(arquivo)\n",
    "        escritor.writerow([\"id_produto\", \"nome_produto\", \"quantidade\",\"ultima_atualizacao\"])\n",
    "        for i in range(1, 6):\n",
    "            escritor.writerow([\n",
    "                i,\n",
    "                produtos[i-1],\n",
    "                random.randint(0,1000),\n",
    "                datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            ])\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#Gerar todso os dados\n",
    "gerar_dados_vendas()\n",
    "gerar_dados_comportamento_cliente()\n",
    "gerar_dados_estoque()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4cd278",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carregar dados de vendas\n",
    "df_vendas = spark.read.csv(\"./dados_vendas.csv\", header=True, inferSchema=True)\n",
    "\n",
    "#carregar dados de comportamento do cliente\n",
    "df_comportamento_cliente = spark.read.json(\"./comportamento_cliente.json\")\n",
    "\n",
    "#carregar dados de estoque\n",
    "df_estoque = spark.read.csv(\"./dados_estoque.csv\" header=True, inferSchema=True)\n",
    "\n",
    "#processar dados de vendas\n",
    "resumo_vendas = df_vendas.groupBy(\"id_produto\", \"produto\") \\\n",
    "    .agg(sum(\"quantidade\").alias(\"quantidade_total_vendida\"),\n",
    "         sum(col(\"quantidade\") * col(\"preco\")).alias(\"receita_total\"))\n",
    "    \n",
    "#Processar dados de comportamento do cliente\n",
    "resumo_comportamento_cleiente = df_comportamento_cliente.groupBy(\"id_produto\",\"acao\")     \\\n",
    "    .count() \\\n",
    "    .groupBy(\"id_produto\") \\\n",
    "    .agg(sum(when(col(\"acao\") == \"visualizacao\", col(\"count\")).otherwise(0)).alias(\"visualizacao\"),\n",
    "         sum(when(col(\"acao\") == \"adicionar_ao_carrinho\", col(\"count\")).otherwise(0)).alias(\"adicionar ao carrinho\"),\n",
    "         sum(when(col(\"acao\") == \"compra\", col(\"count\")).otherwise(0)).alias(\"compras\"),\n",
    "         sum(when(col(\"acao\") == \"avaliacao\", col(\"count\")).otherwise(0)).alias(\"avaliacoes\"))\n",
    "        \n",
    "#processar dados de estoque\n",
    "produtos_baixo_estoque = df_estoque.filter(col(\"quantidade\") < 100)\n",
    "\n",
    "#Juntar dados de vendas e estoque\n",
    "vendas_estoque = resumo_vendas.join(df_estoque, resumo_vendas.id_produto == df_estoque.id_produto)\n",
    "\n",
    "\n",
    "#Calcular produtos mais vendidos om baixo estoque\n",
    "\n",
    "mais_vendidos_baixo_estoque = vendas_estoque.filter(col(\"quantidade\") < 100) \\\n",
    "    .orderBy(col(\"Quantidade_total_vendida\").desc()) \\\n",
    "    .limit(5)\n",
    "    \n",
    "#Analisar comportamento do cliente para produtos mais vendidos\n",
    "produtos_top = resumo_vendas.orderBy(col(\"quantidade_total_vendida\").desc()).limit(5)\n",
    "comportamento_produtos_top = resumo_comportamento_cleiente.join(produtos_top, resumo_comportamento_cleiente.id_produto)\n",
    "\n",
    "\n",
    "#Calcular taxa de conversão\n",
    "\n",
    "taxa_conversao = resumo_comportamento_cleiente.withColumn(\"taxa_conversao\", col(\"compras\")/col(\"visulizacoes\") + 0.1)# adicionar 0.1 para evitar dividir por zero\n",
    "\n",
    "print(\"Top 5 produtos mais vendidos com baixo estoque:\")\n",
    "mais_vendidos_baixo_estoque.show()\n",
    "\n",
    "print(\"\\nxomportamento do cliente para os produtos mais vendidos:\")\n",
    "comportamento_produtos_top.show()\n",
    "\n",
    "print(\"\\nTaxa de conversão por produto:\")\n",
    "taxa_conversao.orderBy(col(\"taxa_conversao\").desc()).show()\n",
    "\n",
    "#Salvar resultado em arquivo csv\n",
    "'''\n",
    "mais_vendidos_baixo_estque.write.csv(\"mais_vendidos_baixo\", header=True)\n",
    "comportamentp_produtos_top.write.csv(\"comportamento_produtos_top.csv, header=True\")\n",
    "taxa_conversao.write.csv(\"taxa_conversao.csv\", header=True)\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
